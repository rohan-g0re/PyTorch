{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Getting Started Tips\n",
        "\n",
        "1. **Start Small**: Begin with CIFAR-10 instead of ImageNet for faster iteration\n",
        "2. **Test Each Phase**: Run verification functions after implementing each phase\n",
        "3. **Debug Shapes**: Print tensor shapes frequently to catch dimension mismatches early\n",
        "4. **Use Small Batches**: Start with small batch sizes to avoid memory issues\n",
        "\n",
        "Work through each function stub systematically. The hints give you the conceptual understanding, but you'll need to research the specific PyTorch APIs and mathematical implementations. Come back with questions about specific functions when you get stuck!\n",
        "\n"
      ],
      "metadata": {
        "id": "xR1XqUe26aYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 1: Environment Setup\n",
        "\n",
        "**Detailed Hint:** You need to establish your development environment with the right deep learning framework. Think about what libraries you'll need for neural networks, computer vision operations, mathematical computations, and data handling. Also consider GPU support if available. The framework choice will determine your entire implementation approach - PyTorch tends to be more research-friendly and closer to how papers describe things.\n"
      ],
      "metadata": {
        "id": "b0SnUniJ5RXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# TODO: Fill in the necessary imports\n",
        "def setup_environment():\n",
        "    \"\"\"\n",
        "    Set up all the necessary imports and check for GPU availability.\n",
        "    Hint: You'll need torch, torchvision, numpy, and possibly matplotlib for visualization.\n",
        "    \"\"\"\n",
        "    # Import statements go here\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    import torchvision\n",
        "    import torchvision.transforms as transforms\n",
        "    import torchvision.datasets as datasets\n",
        "    import torch.utils.data as data\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch.nn\n",
        "    import torch.nn.functional as F\n",
        "    from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "\n",
        "    import time\n",
        "\n",
        "\n",
        "\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from tqdm import tqdm\n",
        "    import random\n",
        "\n",
        "\n",
        "    # Check if CUDA is available\n",
        "    device = None  # TODO: Determine if you should use 'cuda' or 'cpu'\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    print(f\"Using device: {device}\")\n",
        "    return device\n",
        "\n",
        "def set_random_seeds(seed=42):\n",
        "    \"\"\"\n",
        "    Set random seeds for reproducibility across different libraries.\n",
        "    Hint: Neural networks involve randomness in initialization, data shuffling, etc.\n",
        "    You want consistent results across runs for debugging.\n",
        "    \"\"\"\n",
        "    # TODO: Set seeds for torch, numpy, and random module\n",
        "\n",
        "    torch.manual_seed(seed)                    # PyTorch CPU random numbers\n",
        "    torch.cuda.manual_seed(seed)               # PyTorch GPU random numbers\n",
        "    torch.cuda.manual_seed_all(seed)           # For multi-GPU setups\n",
        "    np.random.seed(seed)                       # NumPy random numbers\n",
        "    random.seed(seed)\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "setup_environment()\n",
        "set_random_seeds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhLpV_0o5Rwy",
        "outputId": "5e2a6d07-5d6a-4cd6-8e1d-1690b5f014df",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:13.215187Z",
          "iopub.execute_input": "2025-08-07T00:26:13.215737Z",
          "iopub.status.idle": "2025-08-07T00:26:24.655682Z",
          "shell.execute_reply.started": "2025-08-07T00:26:13.215711Z",
          "shell.execute_reply": "2025-08-07T00:26:24.655003Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Phase 2: Data Preprocessing \\& Augmentation\n",
        "\n",
        "**Detailed Hint:** AlexNet's power comes partly from its data augmentation strategy. You need to think about how to transform images during training vs testing. During training, you want randomness (different crops, flips) to artificially expand your dataset. During testing, you want consistency and thoroughness (systematic crops). The original paper mentions specific image sizes: input images are 256×256, but the network expects 224×224 patches. Consider what happens to the \"extra\" 32 pixels on each side."
      ],
      "metadata": {
        "id": "g6_X9BBp5a6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_basic_transforms():\n",
        "    \"\"\"\n",
        "    Create the basic image transformations for AlexNet.\n",
        "    Hint: Think about the paper's mention of 256×256 input images and 224×224 patches.\n",
        "    What mathematical operations convert images to the right format for neural networks?\n",
        "    \"\"\"\n",
        "    # TODO: Compose transformations for training\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "\n",
        "         transforms.Resize(256),\n",
        "         transforms.RandomResizedCrop(224),\n",
        "         transforms.RandomHorizontalFlip(p=0.5),\n",
        "\n",
        "         #as 3 transformations were listed in paper, we have done all three --> now convert to tensor and move ahead\n",
        "         transforms.ToTensor(),\n",
        "\n",
        "\n",
        "         #normalization is apparrently a standard practice --> ON THE OTHER HAND,\n",
        "         # the numbers chosen are a standard practice for ImageNet\n",
        "\n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Compose transformations for validation/testing\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "\n",
        "        #we choose centre crop bcoz it is deterministic which is what we want in validation set -->\n",
        "        #or else each time our val acc will be different due to flips and randomk crops -->\n",
        "        #hence we also skop the flips\n",
        "\n",
        "        transforms.CenterCrop(224),\n",
        "\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                           std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform, test_transform\n"
      ],
      "metadata": {
        "id": "xigpmzwi5cmV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:24.656950Z",
          "iopub.execute_input": "2025-08-07T00:26:24.657317Z",
          "iopub.status.idle": "2025-08-07T00:26:24.662589Z",
          "shell.execute_reply.started": "2025-08-07T00:26:24.657296Z",
          "shell.execute_reply": "2025-08-07T00:26:24.662002Z"
        }
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_ten_test_crops(image_tensor):\n",
        "    \"\"\"\n",
        "    Extract the 10 crops used during AlexNet testing phase.\n",
        "    Hint: The paper mentions \"four corner patches and the center patch\" plus their horizontal reflections.\n",
        "    Think about where these 5 locations would be in a 256×256 image when extracting 224×224 patches.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    Input: image_tensor: PyTorch tensor of shape [C, H, W]\n",
        "    --> where C (Channels) =3 (RGB)\n",
        "    -->  H (Height) = W (Width) = 256\n",
        "\n",
        "    Output: list of 10 image tensors of shape [C, 224, 224]\n",
        "    \"\"\"\n",
        "    crops = []\n",
        "\n",
        "    # Verifying image_tensor shape is correct\n",
        "\n",
        "    assert image_tensor.dim() == 3, f\"Expected 3D tensor [C,W,H], got {image_tensor.dim()} D\"\n",
        "\n",
        "    assert image_tensor.shape[-2:] == (256, 256), f\"Expected 256x256 image, got with shape {image_tensor.shape[-2:]} \"\n",
        "\n",
        "    # TODO: Extract 4 corner crops (top-left, top-right, bottom-left, bottom-right)\n",
        "\n",
        "\n",
        "# first is colon bcoz we are taking all channels (RGB)\n",
        "\n",
        "    top_left = image_tensor[:, 0:224, 0:224]\n",
        "    crops.append(top_left)\n",
        "\n",
        "    # Top-right corner crop\n",
        "    top_right = image_tensor[:, 0:224, 32:256]  # 256-224=32, so start at col 32\n",
        "    crops.append(top_right)\n",
        "\n",
        "    # Bottom-left corner crop\n",
        "    bottom_left = image_tensor[:, 32:256, 0:224]  # Start at row 32\n",
        "    crops.append(bottom_left)\n",
        "\n",
        "    # Bottom-right corner crop\n",
        "    bottom_right = image_tensor[:, 32:256, 32:256]  # Start at (32, 32)\n",
        "    crops.append(bottom_right)\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Extract center crop\n",
        "\n",
        "    center = image_tensor[:, 16:240, 16:240]\n",
        "    crops.append(center)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Create horizontal flips of all 5 crops\n",
        "\n",
        "\n",
        "    #writing 5 bcoz if that is abset then at every iteration,\n",
        "    # the appended crop will also be considered --> infinite loop\n",
        "    for crop in crops[:5]:\n",
        "\n",
        "# ---------->>>>  IMPORTANT -> torch.flip() with dims=[-1] flips along the last dimension (width)\n",
        "\n",
        "\n",
        "      flipped_crop = torch.flip(crop, dims=[-1])\n",
        "      crops.append(flipped_crop)\n",
        "\n",
        "\n",
        "      #verif=ying if we have 10 crops or other count\n",
        "    assert len(crops) == 10, f\"Expected 10 crops, got {len(crops)}\"\n",
        "\n",
        "      # Verify all crops have correct shape\n",
        "    for i, crop in enumerate(crops):\n",
        "        assert crop.shape == (3, 224, 224), f\"Crop {i} has wrong shape: {crop.shape}\"\n",
        "\n",
        "    return crops  # Should return list of 10 image tensors\n"
      ],
      "metadata": {
        "id": "0dCkSlRcHMqo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:24.663352Z",
          "iopub.execute_input": "2025-08-07T00:26:24.664054Z",
          "iopub.status.idle": "2025-08-07T00:26:24.683631Z",
          "shell.execute_reply.started": "2025-08-07T00:26:24.664035Z",
          "shell.execute_reply": "2025-08-07T00:26:24.682947Z"
        },
        "_kg_hide-input": false
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def implement_pca_color_augmentation(dataset_path):\n",
        "    \"\"\"\n",
        "    Optional advanced function: Implement PCA-based color augmentation.\n",
        "    Hint: You need to collect RGB pixel values from your entire dataset,\n",
        "    compute the covariance matrix, find eigenvectors/eigenvalues,\n",
        "    then create a transform that adds random combinations of these principal components.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # This is advanced - skip if you want to focus on core architecture first\n",
        "\n",
        "    # we willlc ome back later\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "5H0kHSrXHM2u",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:24.685309Z",
          "iopub.execute_input": "2025-08-07T00:26:24.685953Z",
          "iopub.status.idle": "2025-08-07T00:26:24.710613Z",
          "shell.execute_reply.started": "2025-08-07T00:26:24.685927Z",
          "shell.execute_reply": "2025-08-07T00:26:24.710111Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 3: Dataset Loading\n",
        "\n",
        "**Detailed Hint:** You need to create data loaders that can efficiently feed batches of images to your network during training. Think about memory management, shuffling strategies, and how to handle different dataset formats. The original AlexNet used ImageNet, but you might start with CIFAR-10 for faster experimentation. Consider what batch size makes sense for your hardware constraints.\n"
      ],
      "metadata": {
        "id": "kwvnfoGX52fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_loaders(batch_size=128):\n",
        "    \"\"\"\n",
        "    Create PyTorch DataLoaders for training and validation.\n",
        "    Hint: You need to handle the directory structure of your dataset.\n",
        "    Think about what arguments DataLoader needs for efficient training (shuffling, number of workers).\n",
        "    \"\"\"\n",
        "    train_transform, val_transform, test_transform = create_basic_transforms()\n",
        "\n",
        "    # TODO: Create dataset objects using torchvision.datasets\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root = \"./data\",\n",
        "        train = True,\n",
        "        transform=train_transform,\n",
        "        download=True\n",
        "    )\n",
        "\n",
        "\n",
        "    val_dataset = datasets.CIFAR10(\n",
        "        root = \"./data\",\n",
        "        train = False,\n",
        "        transform=val_transform,\n",
        "        download=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Print dataset information\n",
        "    print(f\"Training dataset size: {len(train_dataset)} images\")\n",
        "    print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
        "    print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
        "    print(f\"Class names: {train_dataset.classes}\")\n",
        "\n",
        "\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(\n",
        "        root=\"./data\",\n",
        "        train=False,\n",
        "        transform=test_transform,\n",
        "        download=True\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Create DataLoader objects\n",
        "    train_loader = DataLoader(\n",
        "        dataset = train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        dataset = val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "\n",
        "    print(f\"Training batches per epoch: {len(train_loader)}\")\n",
        "    print(f\"Validation batches: {len(val_loader)}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ],
      "metadata": {
        "id": "aQzJA93f5ajq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:24.711298Z",
          "iopub.execute_input": "2025-08-07T00:26:24.711711Z",
          "iopub.status.idle": "2025-08-07T00:26:24.728553Z",
          "shell.execute_reply.started": "2025-08-07T00:26:24.711686Z",
          "shell.execute_reply": "2025-08-07T00:26:24.728068Z"
        }
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def verify_data_loading(data_loader):\n",
        "    \"\"\"\n",
        "    Test function to verify your data loading works correctly.\n",
        "    Hint: Grab a batch, check the shapes, verify the data types and value ranges.\n",
        "    Print out some statistics to ensure everything looks reasonable.\n",
        "    \"\"\"\n",
        "    # TODO: Get one batch from the data loader\n",
        "\n",
        "    data_iter = iter(data_loader)\n",
        "    images, labels = next(data_iter)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Print shapes and data types\n",
        "    print(f\"Batch images shape: {images.shape}\")  # Should be [batch_size, 3, 224, 224]\n",
        "    print(f\"Batch labels shape: {labels.shape}\")  # Should be [batch_size]\n",
        "    print(f\"Images data type: {images.dtype}\")    # Should be torch.float32\n",
        "    print(f\"Labels data type: {labels.dtype}\")    # Should be torch.int64\n",
        "\n",
        "    # Check value ranges\n",
        "    print(f\"Image pixel value range: [{images.min():.3f}, {images.max():.3f}]\")\n",
        "    print(f\"Label range: [{labels.min()}, {labels.max()}]\")\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Print shapes, min/max values, data types\n",
        "    # TODO: Maybe visualize a few images to verify augmentations work\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "p-6XwcoTWBVK",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:24.729185Z",
          "iopub.execute_input": "2025-08-07T00:26:24.729430Z",
          "iopub.status.idle": "2025-08-07T00:26:24.749332Z",
          "shell.execute_reply.started": "2025-08-07T00:26:24.729407Z",
          "shell.execute_reply": "2025-08-07T00:26:24.748866Z"
        }
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader, val_loader, test_loader = create_data_loaders()\n",
        "verify_data_loading(train_loader)\n",
        "verify_data_loading(val_loader)\n",
        "verify_data_loading(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk65D0cxXKhb",
        "outputId": "cf9c2cc1-c1fe-420d-a52f-5da12e5e42bb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:24.749962Z",
          "iopub.execute_input": "2025-08-07T00:26:24.750148Z",
          "iopub.status.idle": "2025-08-07T00:26:33.002428Z",
          "shell.execute_reply.started": "2025-08-07T00:26:24.750133Z",
          "shell.execute_reply": "2025-08-07T00:26:33.001653Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 42.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 50000 images\n",
            "Validation dataset size: 10000 images\n",
            "Number of classes: 10\n",
            "Class names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Training batches per epoch: 391\n",
            "Validation batches: 79\n",
            "Batch images shape: torch.Size([128, 3, 224, 224])\n",
            "Batch labels shape: torch.Size([128])\n",
            "Images data type: torch.float32\n",
            "Labels data type: torch.int64\n",
            "Image pixel value range: [-2.118, 2.640]\n",
            "Label range: [0, 9]\n",
            "Batch images shape: torch.Size([128, 3, 224, 224])\n",
            "Batch labels shape: torch.Size([128])\n",
            "Images data type: torch.float32\n",
            "Labels data type: torch.int64\n",
            "Image pixel value range: [-2.118, 2.640]\n",
            "Label range: [0, 9]\n",
            "Batch images shape: torch.Size([32, 3, 256, 256])\n",
            "Batch labels shape: torch.Size([32])\n",
            "Images data type: torch.float32\n",
            "Labels data type: torch.int64\n",
            "Image pixel value range: [-2.118, 2.640]\n",
            "Label range: [0, 9]\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 4: Local Response Normalization (LRN)\n",
        "\n",
        "**Detailed Hint:** This is AlexNet's \"secret sauce\" for competition between feature maps. You're implementing the formula from the paper where each activation gets normalized by its neighbors. Think about how to efficiently compute the sum of squares across nearby channels for each spatial location. PyTorch removed built-in LRN, so you need to implement it as a custom module. Consider the sliding window of channels and how to handle edge cases.\n"
      ],
      "metadata": {
        "id": "xU9uxsai550Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LocalResponseNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement Local Response Normalization as described in AlexNet paper.\n",
        "    Hint: The formula involves looking at nearby channels and computing their squared sum.\n",
        "    You need to implement the forward pass that applies the mathematical formula to each activation.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def __init__(self, size=5, alpha=1e-4, beta=0.75, k=2.0):\n",
        "        \"\"\"\n",
        "        Initialize LRN parameters.\n",
        "\n",
        "        Args:\n",
        "            size (int): Number of nearby channels to consider (n in paper)\n",
        "            alpha (float): Scaling parameter (α in paper)\n",
        "            beta (float): Exponent parameter (β in paper)\n",
        "            k (float): Additive constant to prevent division by zero\n",
        "        \"\"\"\n",
        "        super(LocalResponseNorm, self).__init__()\n",
        "        self.size = size\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.k = k\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Apply LRN to input tensor x.\n",
        "\n",
        "        Hint: x has shape [batch, channels, height, width]\n",
        "\n",
        "        For each position, you need to look at 'size' nearby channels,\n",
        "        compute the sum of their squares, then apply the normalization formula.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, channels, height, width = x.size()\n",
        "\n",
        "        # TODO: Implement the LRN formula\n",
        "\n",
        "        # Step 1: Squaring the input\n",
        "\n",
        "        x_squared = x.pow(2)\n",
        "\n",
        "\n",
        "        #step 2:  Padding\n",
        "\n",
        "        #Step 2.1: Calculate how much padding we need:\n",
        "\n",
        "        padding = self.size // 2\n",
        "\n",
        "\n",
        "        # step 2.2: add the padding using the FANCY SYNTAX\n",
        "\n",
        "        x_squared_padded = F.pad(\n",
        "            x_squared,\n",
        "            (0, 0, 0, 0, padding, padding),\n",
        "            mode='constant',\n",
        "            value=0\n",
        "        )\n",
        "       # x_squared_padded shape: [batch, channels + 2*padding, height, width]\n",
        "\n",
        "\n",
        "        # Step 3: Sliding Window\n",
        "\n",
        "        # Step 3.1: Store the window states/conditions\n",
        "\n",
        "        windows = x_squared_padded.unfold(1, self.size, 1)\n",
        "\n",
        "\n",
        "        # Step 3.2: Calculate sum for each window condition\n",
        "\n",
        "        sum_of_squares = windows.sum(dim=-1)\n",
        "\n",
        "# hence we got the \"summation\" term of equation\n",
        "\n",
        "\n",
        "        denominator = torch.pow(self.k + self.alpha * sum_of_squares, self.beta)\n",
        "        denominator = torch.clamp(denominator, min=1e-8) # --> to avoid division by zero\n",
        "\n",
        "        return x / denominator  # Return normalized tensor"
      ],
      "metadata": {
        "id": "4efyN8XT55kM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:33.003418Z",
          "iopub.execute_input": "2025-08-07T00:26:33.003892Z",
          "iopub.status.idle": "2025-08-07T00:26:33.011362Z",
          "shell.execute_reply.started": "2025-08-07T00:26:33.003847Z",
          "shell.execute_reply": "2025-08-07T00:26:33.010799Z"
        }
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 5: AlexNet Architecture\n",
        "\n",
        "**Detailed Hint:** Now you're building the actual network described in the paper. Think about the sequence: convolutional layers extract features, pooling layers reduce spatial dimensions, fully connected layers make final classifications. Pay attention to the paper's specific numbers: kernel sizes, strides, number of filters, etc. The architecture has two main parts - feature extraction (convolutional) and classification (fully connected). Consider where dropout and LRN fit in the architecture.\n"
      ],
      "metadata": {
        "id": "lvMG4a5r6Avj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Implement the full AlexNet architecture.\n",
        "    Hint: The paper describes 5 convolutional layers followed by 3 fully connected layers.\n",
        "    Pay attention to the specific parameters: kernel sizes, strides, padding, number of filters.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        self.features = self._make_feature_layers()\n",
        "        self.classifier = self._make_classifier_layers(num_classes)\n",
        "\n",
        "        # TODO: Initialize weights using the strategy mentioned in the paper\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _make_feature_layers(self):\n",
        "        \"\"\"\n",
        "        Create the convolutional feature extraction layers.\n",
        "\n",
        "        Hint: Look at the paper's Table 1 or Figure 2 for the exact layer specifications.\n",
        "\n",
        "        Remember to include ReLU activations, LRN where specified, and MaxPooling layers.\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "\n",
        "        # TODO: Add Conv2d, ReLU, LRN, MaxPool2d in the right sequence\n",
        "\n",
        "\n",
        "  # ----------- Layer 1: Conv(11x11, 96 filters, stride 4) -> ReLU -> LRN -> MaxPool -----------\n",
        "\n",
        "\n",
        "        # Large 11x11 kernel to capture big patterns, stride=4 to reduce size quickly\n",
        "\n",
        "\n",
        "        layers.append(nn.Conv2d(\n",
        "            in_channels=3,          # RGB input\n",
        "            out_channels=96,        # 96 different pattern detectors\n",
        "            kernel_size=11,         # 11x11 sliding window\n",
        "            stride=4,               # Move 4 pixels at a time (reduces size)\n",
        "            padding=2               # Add border to maintain reasonable size\n",
        "\n",
        "        ))\n",
        "\n",
        "\n",
        "        layers.append(nn.ReLU(inplace=True))  # Activation: keep positive values only\n",
        "\n",
        "        # Add Local Response Normalization (from your Phase 4 implementation)\n",
        "        layers.append(LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0))\n",
        "\n",
        "        # MaxPooling: Take the maximum in each 3x3 region, stride=2\n",
        "        layers.append(nn.MaxPool2d(kernel_size=3, stride=2))\n",
        "\n",
        "\n",
        "        # ----------- Layer 2: Conv(5x5, 256 filters, stride 1) -> ReLU -> LRN -> MaxPool  -----------\n",
        "\n",
        "\n",
        "        # Input: 96 channels -> Output: 256 feature maps\n",
        "        # Smaller 5x5 kernel for more detailed patterns\n",
        "\n",
        "\n",
        "        # We implement the FULL network on one device\n",
        "        layers.append(nn.Conv2d(96, 256, kernel_size=5, padding=2))\n",
        "        #                       ↑    ↑\n",
        "        #                       96   256\n",
        "        #                       │    └─ Total output channels\n",
        "        #                       └─ Total input channels (96, not 48) --> bcoz 48 are split across 2 GPUs according to the paper.\n",
        "\n",
        "\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        layers.append(LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0))\n",
        "\n",
        "        layers.append(nn.MaxPool2d(kernel_size=3, stride=2))\n",
        "\n",
        "\n",
        "\n",
        "        # ----------- Layer 3: Conv(3x3, 384 filters, stride 1) -> ReLU -----------\n",
        "\n",
        "\n",
        "        # Input: 256 channels -> Output: 384 feature maps\n",
        "        # Even smaller 3x3 kernel for fine details\n",
        "\n",
        "\n",
        "        layers.append(nn.Conv2d(256, 384, kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "\n",
        "        # ----------- Layer 4: Conv(3x3, 384 filters, stride 1) -> ReLU -----------\n",
        "\n",
        "        # Input: 384 channels -> Output: 384 feature maps\n",
        "        # Same size, just processing the features further\n",
        "\n",
        "        layers.append(nn.Conv2d(384, 384, kernel_size=3, padding=1))\n",
        "\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "       # ----------- Layer 5: Conv(3x3, 256 filters, stride 1) -> ReLU -> MaxPool -----------\n",
        "\n",
        "        # Input: 384 channels -> Output: 256 feature maps\n",
        "        # Final feature extraction layer\n",
        "        layers.append(nn.Conv2d(384, 256, kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.MaxPool2d(kernel_size=3, stride=2))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _make_classifier_layers(self, num_classes):\n",
        "        \"\"\"\n",
        "        Create the fully connected classification layers.\n",
        "        Hint: The paper mentions 3 fully connected layers with specific dimensions.\n",
        "        Don't forget dropout for regularization - where should it be applied?\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "\n",
        "        # TODO: Add Linear layers with appropriate input/output dimensions\n",
        "\n",
        "        # TODO: Add ReLU activations and Dropout where appropriate\n",
        "\n",
        "        # DROPOUT: Randomly turn off 50% of neurons during training\n",
        "        # This prevents overfitting - like studying with distractions to build robustness\n",
        "        layers.append(nn.Dropout(p=0.5))\n",
        "\n",
        "\n",
        "\n",
        "        # FULLY CONNECTED LAYER 1\n",
        "        # Input: 256 * 6 * 6 = 9216 features (flattened from conv layers)\n",
        "        # Output: 4096 neurons\n",
        "        layers.append(nn.Linear(256 * 6 * 6, 4096))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "        # More dropout\n",
        "        layers.append(nn.Dropout(p=0.5))\n",
        "\n",
        "\n",
        "        # FULLY CONNECTED LAYER 2\n",
        "        # Input: 4096 -> Output: 4096\n",
        "        layers.append(nn.Linear(4096, 4096))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "\n",
        "        # Final layer should output 'num_classes' values (no activation - handled by loss function)\n",
        "\n",
        "        # Input: 4096 -> Output: num_classes (10 for CIFAR-10, 1000 for ImageNet)\n",
        "        # No activation here - the loss function (CrossEntropy) handles it\n",
        "        layers.append(nn.Linear(4096, num_classes))\n",
        "\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"\n",
        "        Initialize network weights as described in the paper.\n",
        "        Hint: The paper mentions specific initialization strategies for different layer types.\n",
        "        Conv layers and Linear layers might need different approaches.\n",
        "        \"\"\"\n",
        "\n",
        "        # we loop over every layer in the network and set weights\n",
        "        for module in self.modules():\n",
        "\n",
        "          # if layer is a conv layer\n",
        "\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                # Convolutional layers: Gaussian distribution with std=0.01\n",
        "\n",
        "                #weights\n",
        "                nn.init.normal_(module.weight, mean=0, std=0.01)\n",
        "\n",
        "                #bias\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "\n",
        "\n",
        "           # if layer is fc layer\n",
        "\n",
        "            elif isinstance(module, nn.Linear):\n",
        "                # Fully connected layers: Gaussian distribution with std=0.01\\\n",
        "\n",
        "              #weights\n",
        "                nn.init.normal_(module.weight, mean=0, std=0.01)\n",
        "\n",
        "                #bias\n",
        "                nn.init.constant_(module.bias, 1)  # Paper initializes FC biases to 1\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      # self - is basically the alexnet network itself\n",
        "      # x is the input image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Define the forward pass through the network.\n",
        "        Hint: Data flows through features, then gets flattened, then through classifier.\n",
        "        Pay attention to tensor shapes - when do you need to reshape?\n",
        "        \"\"\"\n",
        "        # TODO: Pass through feature extraction layers\n",
        "\n",
        "\n",
        "        #step 1: feature extraction layers\n",
        "        #pass through all conv layers\n",
        "        # Input shape: [batch_size, 3, 224, 224]\n",
        "        # Output shape: [batch_size, 256, 6, 6]\n",
        "\n",
        "\n",
        "        x = self.features(x)\n",
        "\n",
        "\n",
        "\n",
        "        '''\n",
        "        Original photo: [Cat sitting on a chair]\n",
        "\n",
        "        Detective's report (256 observations):\n",
        "        - Report 1: \"I see vertical edges in regions...\"\n",
        "        - Report 2: \"I see curved shapes in regions...\"\n",
        "        - Report 3: \"I see furry textures in regions...\"\n",
        "        - Report 4: \"I see pointy triangular shapes in regions...\"\n",
        "        - ...\n",
        "        - Report 256: \"I see whisker-like patterns in regions...\"\n",
        "\n",
        "        ----- tHEREFORE we get the shape change as ------\n",
        "\n",
        "\n",
        "        # Before feature extraction:\n",
        "        # x.shape = [batch_size, 3, 224, 224]\n",
        "        #           [how many photos, RGB, height, width]\n",
        "        #           [4, 3, 224, 224] = 4 color photos, each 224×224 pixels\n",
        "\n",
        "        # After feature extraction:\n",
        "        # x.shape = [batch_size, 256, 6, 6]\n",
        "        #           [how many photos, observations, small regions, small regions]\n",
        "        #           [4, 256, 6, 6] = 4 analysis reports, each with 256 observations about 6×6 grid\n",
        "        '''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Flatten the tensor for fully connected layers\n",
        "        # Step 2: flatten bcoz we need to convert from 4d tensor to 2d tensore\n",
        "\n",
        "       # Think: Convert from \"image with features\" to \"list of features\"\n",
        "\n",
        "        x = x.view(x.size(0), -1) # Keep batch size, flatten everything else\n",
        "\n",
        "        # continuation from example: turning the report into a list\n",
        "\n",
        "        # New shape: [batch_size, 256*6*6] = [batch_size, 9216]\n",
        "\n",
        "        #we have done this bcoz FC layers need a list of numbers and not grids\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Step 3: Pass through classifier layers\n",
        "\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        # gives us the final class label\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "OtsUJXu75bWM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:33.012225Z",
          "iopub.execute_input": "2025-08-07T00:26:33.012911Z",
          "iopub.status.idle": "2025-08-07T00:26:33.045423Z",
          "shell.execute_reply.started": "2025-08-07T00:26:33.012884Z",
          "shell.execute_reply": "2025-08-07T00:26:33.044730Z"
        }
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 6: Training Infrastructure\n",
        "\n",
        "**Detailed Hint:** You need to set up the training loop components: loss function, optimizer, and learning rate scheduling. The paper mentions specific choices - cross-entropy loss, SGD with momentum, specific learning rates and weight decay values. Think about what each hyperparameter does and why the authors chose these values. Also consider how to track and display training progress.\n"
      ],
      "metadata": {
        "id": "LIb-0r_X6GYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def setup_training_components(model, learning_rate=0.01):\n",
        "    \"\"\"\n",
        "    Set up loss function, optimizer, and learning rate scheduler.\n",
        "\n",
        "    Hint: AlexNet paper specifies SGD with momentum, specific weight decay values.\n",
        "\n",
        "    What loss function makes sense for multi-class classification?\n",
        "    \"\"\"\n",
        "    # TODO: Define appropriate loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # TODO: Define optimizer with paper's hyperparameters\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),           # Which weights to update\n",
        "        lr=learning_rate,            # How big steps to take (learning rate)\n",
        "        momentum=0.9,                # How much to remember previous updates\n",
        "        weight_decay=0.0005          # Regularization to prevent overfitting\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # TODO: Optional - create learning rate scheduler\n",
        "\n",
        "\n",
        "    # LEARNING RATE SCHEDULER - When to change learning speed\n",
        "    # AlexNet reduces LR by factor of 10 when validation error stops improving\n",
        "    scheduler = ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',          # Reduce LR when validation loss stops decreasing\n",
        "        factor=0.1,          # Multiply LR by 0.1 (reduce by factor of 10)\n",
        "        patience=1,         # Wait 10 epochs before reducing\n",
        "        verbose=True         # Print when LR changes\n",
        "    )\n",
        "\n",
        "    return criterion, optimizer, scheduler\n"
      ],
      "metadata": {
        "id": "8S3HgFrzyuU2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:33.047340Z",
          "iopub.execute_input": "2025-08-07T00:26:33.047779Z",
          "iopub.status.idle": "2025-08-07T00:26:33.067136Z",
          "shell.execute_reply.started": "2025-08-07T00:26:33.047755Z",
          "shell.execute_reply": "2025-08-07T00:26:33.066458Z"
        }
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"\n",
        "    Execute one training epoch.\n",
        "    Hint: This is your main training loop - iterate through batches,\n",
        "    compute forward pass, calculate loss, backpropagate, update weights.\n",
        "    Track metrics like loss and accuracy for monitoring.\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time= time.time()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        # TODO: Move data to appropriate device\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "\n",
        "        # TODO: Zero gradients\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Forward pass\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        \"\"\"\n",
        "        Example output from AlexNet:\n",
        "\n",
        "        AlexNet's guess: [0.1, 0.8, 0.05, 0.02, 0.01, 0.01, 0.005, 0.005, 0.0, 0.0]\n",
        "        Class meanings:  [plane, car, bird, cat, deer, dog, frog, horse, ship, truck]\n",
        "        Translation: \"I'm 80% confident this is a car, 10% confident it's a plane...\"\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # TODO: Compute loss\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "\n",
        "# --------- STARTING BACKPROP---------\n",
        "\n",
        "        # TODO: Backward pass\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        \"\"\"\n",
        "        computes gradients WRT all model parameters\n",
        "        - model parameteres here (i think) is the 'theta' which is basically all the weights and biases\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Optimizer step\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Update running statistics\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        predicted = torch.argmax(output, dim=1)  # Get class with highest probability\n",
        "        total += target.size(0)                  # Add batch size to total\n",
        "        correct += (predicted == target).sum().item()  # Count correct predictions\n",
        "\n",
        "\n",
        "        # Optional: Print progress every N batches\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "          current_acc = 100.0 * correct / total\n",
        "          print(f\"  Batch {batch_idx:4d}/{len(train_loader)}: \"\n",
        "                f\"Loss: {loss.item():.4f}, \"\n",
        "                f\"Accuracy: {current_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "id": "LDYzb5rIywkK",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:33.067962Z",
          "iopub.execute_input": "2025-08-07T00:26:33.068210Z",
          "iopub.status.idle": "2025-08-07T00:26:33.087858Z",
          "shell.execute_reply.started": "2025-08-07T00:26:33.068193Z",
          "shell.execute_reply": "2025-08-07T00:26:33.087331Z"
        }
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def validate_model(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate model on validation set.\n",
        "    Hint: Similar to training but without gradient computation.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    \"\"\"\n",
        "    # Evaluation mode: model.eval()\n",
        "    # - Dropout is DISABLED (all neurons active for best performance)\n",
        "    # - BatchNorm uses stored statistics from training\n",
        "    # - Network gives its \"best shot\" consistently\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad(): # as specified earlier -->  no need of calculating gradients\n",
        "\n",
        "        for data, target in val_loader:\n",
        "\n",
        "            \"\"\"\n",
        "            ALMOST SIMILAR JUS THAT -->\n",
        "            1. we are doing this for monitoring the performance of model and not to make it better\n",
        "            --> thats why we dont have a backprop process\n",
        "            --> just simple calculating loss and accuracy\n",
        "\n",
        "            2. we do all of this on DIFFERENT DATA - loaded usnig val_loader ---> NEVER SEEN BEFORE\n",
        "\n",
        "            ]\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "            IMP ------ During validation, we want to see AlexNet's true current ability, not give it more practice!\n",
        "            \"\"\"\n",
        "\n",
        "            # TODO: Move data to device\n",
        "\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "\n",
        "            # TODO: Forward pass\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            # TODO: Compute loss\n",
        "\n",
        "            # this loss is not calculated for learning --> we are just checking/monitoring using this loss\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "\n",
        "            # TODO: Calculate accuracy\n",
        "\n",
        "            predicted = torch.argmax(output, dim=1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "\n",
        "    avg_loss = val_loss / len(val_loader)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "YlYizrYU6DrG",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:26:33.088588Z",
          "iopub.execute_input": "2025-08-07T00:26:33.088817Z",
          "iopub.status.idle": "2025-08-07T00:26:33.111276Z",
          "shell.execute_reply.started": "2025-08-07T00:26:33.088801Z",
          "shell.execute_reply": "2025-08-07T00:26:33.110798Z"
        }
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 7: Main Training Loop\n",
        "\n",
        "**Detailed Hint:** This ties everything together - your main training script that orchestrates the entire process. Think about how many epochs to train, when to save checkpoints, how to handle early stopping, and what information to log. Consider what you want to track during training and how to save the best model.\n"
      ],
      "metadata": {
        "id": "Beb02V9u6K0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_alexnet(num_epochs=1, save_path=\"alexnet_checkpoint.pth\", resume_training=True):\n",
        "    \"\"\"\n",
        "    Main training function that coordinates everything.\n",
        "    Hint: This should set up all components, then run training/validation loops.\n",
        "    Consider saving checkpoints, tracking best performance, and logging progress.\n",
        "\n",
        "    this will return model --> which we did not have earlier\n",
        "    it will also return best_val_acc as before\n",
        "    \"\"\"\n",
        "    # TODO: Set up device, data loaders, model, training components\n",
        "    device = setup_environment()\n",
        "    train_loader, val_loader, _ = create_data_loaders(batch_size = 256)\n",
        "    model = AlexNet(num_classes=10).to(device)\n",
        "    criterion, optimizer, scheduler = setup_training_components(model, learning_rate=0.01)\n",
        "\n",
        "\n",
        "    # Initializing tracking variables for a LOT of things\n",
        "    best_val_acc = 0.0\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    start_epoch = 0 # required if we load the model which was already trained till \"x\" epochs\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    before training we need to check if we already have a trained/saved model\n",
        "\n",
        "    Therefore we need to have logic to load that model\n",
        "    AND to use its metadata for initializing our training journey\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if resume_training and os.path.exists(save_path):\n",
        "        print (\"loading checkpoint\")\n",
        "\n",
        "        try:\n",
        "\n",
        "            checkpoint = torch.load(save_path, map_location = device)\n",
        "\n",
        "\n",
        "            # loading ----->>>>> MODEL WIGHTS\n",
        "\n",
        "            model.load_state_dict (checkpoint['model_state_dict'])\n",
        "\n",
        "\n",
        "            # loading ------>>>>> optimizer and scheduler states\n",
        "\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "\n",
        "            # Loading ------->>>>>>> training progress\n",
        "\n",
        "            start_epoch = checkpoint.get('epoch', 0)\n",
        "\n",
        "            best_val_acc = checkpoint.get('best_val_acc', 0.0)\n",
        "            best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
        "\n",
        "\n",
        "            print (\"checkpoint loaded\")\n",
        "\n",
        "        except Exception as e:\n",
        "\n",
        "            print (\"model was there apparently but unable to load\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        print (\"training fresh init\")\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    ---------------- model loading code ended ------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ---------------- training loop strats below ------------------------\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        epoch_start_time = time.time()\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "        # TODO: Train for one epoch\n",
        "\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "\n",
        "        # TODO: Validate the model\n",
        "\n",
        "        val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Update learning rate if using scheduler\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Check if learning rate was reduced\n",
        "        new_lr = optimizer.param_groups[0]['lr']\n",
        "        if new_lr != current_lr:\n",
        "            print(f\" ----- Learning rate reduced: {current_lr:.6f} → {new_lr:.6f}\")\n",
        "\n",
        "\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Save checkpoint if this is the best model so far\n",
        "\n",
        "        is_best_flag = val_acc > best_val_acc\n",
        "\n",
        "        if is_best_flag:\n",
        "            best_val_acc = val_acc\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0\n",
        "\n",
        "\n",
        "            # Creating a list of things that we need to save\n",
        "\n",
        "            checkpoint = {\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'scheduler_state_dict': scheduler.state_dict(),\n",
        "                'best_val_acc': best_val_acc,\n",
        "                'best_val_loss': best_val_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'train_loss': train_loss,\n",
        "                'val_acc': val_acc,\n",
        "                'val_loss': val_loss\n",
        "            }\n",
        "\n",
        "\n",
        "            torch.save(checkpoint, save_path)\n",
        "            print (\"new best model saved\")\n",
        "\n",
        "\n",
        "\n",
        "# if the model did not get saved - it means that model was not better - which means no improvement\n",
        "\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "\n",
        "\n",
        "        # TODO: Print/log progress\n",
        "        print(f\"\\n EPOCH {epoch+1} SUMMARY:\")\n",
        "        print(f\"   Time: {epoch_time:.1f}s\")\n",
        "        print(f\"   Train → Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
        "        print(f\"   Val   → Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
        "        print(f\"   Best Val Acc: {best_val_acc:.2f}% (Epoch {epoch + 1 - epochs_without_improvement})\")\n",
        "\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "\n",
        "\n",
        "    #Most IMP return the model\n",
        "    return model, best_val_acc\n"
      ],
      "metadata": {
        "id": "WGjyc2tv6Iym",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:31:09.983393Z",
          "iopub.execute_input": "2025-08-07T00:31:09.983732Z",
          "iopub.status.idle": "2025-08-07T00:31:09.994864Z",
          "shell.execute_reply.started": "2025-08-07T00:31:09.983705Z",
          "shell.execute_reply": "2025-08-07T00:31:09.994093Z"
        }
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "model, best_val_acc = train_alexnet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-BSGWu8YgSU",
        "outputId": "a5efb52a-770d-4523-d294-74688c8594d8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:34:28.764081Z",
          "iopub.execute_input": "2025-08-07T00:34:28.764880Z",
          "iopub.status.idle": "2025-08-07T00:36:18.904871Z",
          "shell.execute_reply.started": "2025-08-07T00:34:28.764847Z",
          "shell.execute_reply": "2025-08-07T00:36:18.903918Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Training dataset size: 50000 images\n",
            "Validation dataset size: 10000 images\n",
            "Number of classes: 10\n",
            "Class names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Training batches per epoch: 196\n",
            "Validation batches: 40\n",
            "training fresh init\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    0/196: Loss: 2.6561, Accuracy: 10.55%\n",
            "  Batch  100/196: Loss: 2.3026, Accuracy: 10.28%\n",
            "new best model saved\n",
            "\n",
            " EPOCH 1 SUMMARY:\n",
            "   Time: 162.9s\n",
            "   Train → Loss: 2.7702, Accuracy: 0.10%\n",
            "   Val   → Loss: 2.3027, Accuracy: 0.10%\n",
            "   Best Val Acc: 0.10% (Epoch 1)\n",
            "Training completed!\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 8: Testing with 10-Crop Strategy\n",
        "\n",
        "**Detailed Hint:** Implement AlexNet's testing strategy where you extract 10 different crops from each test image and average their predictions. This is different from training where you use random crops. Think about how this averaging helps improve accuracy and robustness.\n"
      ],
      "metadata": {
        "id": "j29BPEEi6QVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_trained_model(checkpoint_path=\"alexnet_checkpoint.pth\", device=None):\n",
        "    \"\"\"\n",
        "    Load a trained AlexNet model from checkpoint.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path: Path to the saved checkpoint\n",
        "        device: Device to load model on (if None, auto-detect)\n",
        "\n",
        "    Returns:\n",
        "        model: Loaded AlexNet model ready for testing\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    print(f\"📥 Loading model from {checkpoint_path}...\")\n",
        "\n",
        "    try:\n",
        "        # Create model architecture\n",
        "        model = AlexNet(num_classes=10).to(device)\n",
        "\n",
        "        # Load checkpoint\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "        # Load model weights\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        # Set to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        print(f\"✅ Model loaded successfully!\")\n",
        "        if 'best_val_acc' in checkpoint:\n",
        "            print(f\"   Best validation accuracy: {checkpoint['best_val_acc']:.2f}%\")\n",
        "        if 'epoch' in checkpoint:\n",
        "            print(f\"   Trained for {checkpoint['epoch']} epochs\")\n",
        "\n",
        "        return model\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ Error: Checkpoint file '{checkpoint_path}' not found!\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:43:13.858114Z",
          "iopub.execute_input": "2025-08-07T00:43:13.858384Z",
          "iopub.status.idle": "2025-08-07T00:43:13.864491Z",
          "shell.execute_reply.started": "2025-08-07T00:43:13.858363Z",
          "shell.execute_reply": "2025-08-07T00:43:13.863679Z"
        },
        "id": "q_zLOMxKDAmA"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "def test_with_ten_crops(model = None, device = None, checkpoint_path = \"alexnet_checkpoint.pth\"):\n",
        "    \"\"\"\n",
        "    Evaluate model using the 10-crop testing strategy from the paper.\n",
        "    Hint: For each test image, extract 10 crops, get predictions for each,\n",
        "    then average the softmax outputs before making final prediction.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # do the \"SETUP\" of things\n",
        "\n",
        "    # 1. setting up device - bcoz it is needed everywhere\n",
        "\n",
        "    device = setup_environment()\n",
        "\n",
        "\n",
        "    # 2. load the model\n",
        "\n",
        "    if model is None:\n",
        "        model = load_trained_model(checkpoint_path, device)\n",
        "\n",
        "\n",
        "    # 3. setup the test data using test loaded\n",
        "\n",
        "    _, _, test_loader = create_data_loaders(batch_size = 256)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # INITIALIZATIONS that are required\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "\n",
        "          labels = labels.to(device)\n",
        "          images = images.to(device)\n",
        "          batch_size = images.size(0)\n",
        "\n",
        "\n",
        "          for i in range (batch_size):\n",
        "\n",
        "            img = images[i]\n",
        "            # Shape = [3, 256, 256]\n",
        "\n",
        "            true_label = labels[i].item()\n",
        "\n",
        "\n",
        "\n",
        "            # TODO: Extract 10 crops from this image\n",
        "            crops = extract_ten_test_crops(img)\n",
        "\n",
        "\n",
        "            # TODO: Get prediction for each crop\n",
        "            crop_predictions = []\n",
        "\n",
        "            for crop in crops:\n",
        "\n",
        "\n",
        "              crop_batch = crop.unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "              # TODO: Forward pass through model\n",
        "\n",
        "              output = model(crop_batch)\n",
        "\n",
        "\n",
        "              # TODO: Apply softmax to get probabilities\n",
        "\n",
        "              probabilities = F.softmax(output, dim=1)  # Convert logits to probabilities\n",
        "\n",
        "              # Store this crop's prediction\n",
        "              crop_predictions.append(probabilities)\n",
        "\n",
        "\n",
        "            # STEP 3: Average the 10 predictions\n",
        "            stacked_predictions = torch.stack(crop_predictions)\n",
        "            avg_prediction = torch.mean(stacked_predictions, dim=0)\n",
        "\n",
        "\n",
        "            # STEP 4: Make final classification decision\n",
        "            predicted_class = torch.argmax(avg_prediction, dim=1).item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # STEP 5: Check if prediction is correct\n",
        "            if predicted_class == true_label:\n",
        "                correct += 1\n",
        "\n",
        "            total += 1\n",
        "\n",
        "          if batch_idx % 20 == 0:\n",
        "                current_acc = 100.0 * correct / total if total > 0 else 0.0\n",
        "                print(f\"  Processed {batch_idx + 1} batches, Current accuracy: {current_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "    final_accuracy = correct / total\n",
        "    print(f\"\\n✅ 10-crop test accuracy: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
        "    return final_accuracy"
      ],
      "metadata": {
        "id": "S1jggrSJ6NjF",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:47:58.691118Z",
          "iopub.execute_input": "2025-08-07T00:47:58.691399Z",
          "iopub.status.idle": "2025-08-07T00:47:58.699853Z",
          "shell.execute_reply.started": "2025-08-07T00:47:58.691374Z",
          "shell.execute_reply": "2025-08-07T00:47:58.699126Z"
        }
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = test_with_ten_crops()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:48:05.265780Z",
          "iopub.execute_input": "2025-08-07T00:48:05.266044Z",
          "iopub.status.idle": "2025-08-07T00:50:21.472841Z",
          "shell.execute_reply.started": "2025-08-07T00:48:05.266023Z",
          "shell.execute_reply": "2025-08-07T00:50:21.471535Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fkdFajdDAmB",
        "outputId": "0f93f710-5bad-44e0-feba-0ed86418c992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "📥 Loading model from alexnet_checkpoint.pth...\n",
            "✅ Model loaded successfully!\n",
            "   Best validation accuracy: 0.10%\n",
            "   Trained for 1 epochs\n",
            "Training dataset size: 50000 images\n",
            "Validation dataset size: 10000 images\n",
            "Number of classes: 10\n",
            "Class names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Training batches per epoch: 196\n",
            "Validation batches: 40\n",
            "  Processed 1 batches, Current accuracy: 3.12%\n",
            "  Processed 21 batches, Current accuracy: 9.38%\n",
            "  Processed 41 batches, Current accuracy: 9.76%\n",
            "  Processed 61 batches, Current accuracy: 9.73%\n",
            "  Processed 81 batches, Current accuracy: 10.46%\n",
            "  Processed 101 batches, Current accuracy: 10.40%\n",
            "  Processed 121 batches, Current accuracy: 10.61%\n",
            "  Processed 141 batches, Current accuracy: 10.48%\n",
            "  Processed 161 batches, Current accuracy: 10.15%\n",
            "  Processed 181 batches, Current accuracy: 10.07%\n",
            "  Processed 201 batches, Current accuracy: 10.00%\n",
            "  Processed 221 batches, Current accuracy: 10.05%\n",
            "  Processed 241 batches, Current accuracy: 10.09%\n",
            "  Processed 261 batches, Current accuracy: 10.00%\n",
            "  Processed 281 batches, Current accuracy: 10.01%\n",
            "  Processed 301 batches, Current accuracy: 9.98%\n",
            "\n",
            "✅ 10-crop test accuracy: 0.1000 (10.00%)\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "print (test_accuracy)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-07T00:50:21.474815Z",
          "iopub.status.idle": "2025-08-07T00:50:21.475027Z",
          "shell.execute_reply.started": "2025-08-07T00:50:21.474928Z",
          "shell.execute_reply": "2025-08-07T00:50:21.474937Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FIm-U5QDAmB",
        "outputId": "42aeb51c-72a0-440f-8a81-cb076d02edd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n"
          ]
        }
      ],
      "execution_count": 22
    }
  ]
}