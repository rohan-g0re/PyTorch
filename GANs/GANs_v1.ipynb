{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1: MNIST Handwritten Digit Dataset"
      ],
      "metadata": {
        "id": "hdYCqFTDHt5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BSuZn6JI_2tU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06wy1qhSJyeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## basic transformations which are mandotory --> i.e converting to tensor and normalization\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "# creating dataset objects - later we will also have dataloader objects\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root = '/data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root = '/data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "print (len(train_dataset))\n",
        "print (len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-C9awMNLBjl",
        "outputId": "fcb9d919-9d41-49cd-e425-b82e3adf071b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the dataset now contains images which can be accessed using train_dataset[x]\n",
        "# each image also has a true label whih is the actual class of that label\n",
        "# currently we are accessing the 69th image --> which turns out to be a zero\n",
        "\n",
        "sample_image, sample_label = train_dataset[69]\n",
        "\n",
        "print (sample_image.shape)\n",
        "print (sample_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obujyUJMOZGW",
        "outputId": "149dc327-77e6-4b09-af25-4a7129799176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets also do it for test dataset\n",
        "# funny enough we have zero as the 69th image in both the datasets\n",
        "\n",
        "sample_image, sample_label = test_dataset[69]\n",
        "\n",
        "print (sample_image.shape)\n",
        "print (sample_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUhhcbWrOyQT",
        "outputId": "613a5a2f-df51-45a5-f7a2-f4c10fd4564f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2: How to Define and Train the Discriminator Model\n"
      ],
      "metadata": {
        "id": "ScgDjlHiUe4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 2.1 Discriminator architecture"
      ],
      "metadata": {
        "id": "2bvtE9YxUkRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "  def __init__ (self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.first_conv_block = self._make_first_conv_block()\n",
        "    self.second_conv_block = self._make_second_conv_block()\n",
        "    self.final_classification_block = self._make_final_classification_block()\n",
        "\n",
        "\n",
        "  def _make_first_conv_block(self):\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 1,\n",
        "            out_channels = 64,\n",
        "            kernel_size = 3,\n",
        "            stride = 2,\n",
        "            padding = 1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2,\n",
        "            inplace = True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.Dropout(\n",
        "            p = 0.4\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _make_second_conv_block(self):\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(\n",
        "        nn.Conv2d(\n",
        "            in_channels = 64,\n",
        "            out_channels = 64,\n",
        "            kernel_size = 3,\n",
        "            stride = 2,\n",
        "            padding = 1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.LeakyReLU(\n",
        "            negative_slope = 0.2,\n",
        "            inplace = True\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(\n",
        "        nn.Dropout(\n",
        "            p = 0.4\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _make_final_classification_block (self):\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    layers.append(nn.Flatten())\n",
        "\n",
        "    layers.append(\n",
        "        nn.Linear(\n",
        "            in_features = 7*7*64,\n",
        "            out_features = 1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "  def forward (self, x):\n",
        "\n",
        "    x = self.first_conv_block(x)\n",
        "    x = self.second_conv_block(x)\n",
        "    x = self.final_classification_block(x)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Ic-AQqN1UtUS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_discriminator():\n",
        "\n",
        "  discriminator = Discriminator()\n",
        "\n",
        "\n",
        "  # in article they have decided to use adam sgd and bce loss\n",
        "\n",
        "\n",
        "  optimizer = optim.Adam(\n",
        "      discriminator.parameters(),\n",
        "      lr = 0.0002,\n",
        "      betas = (0.5, 0.999)\n",
        "  )\n",
        "\n",
        "  criterion = nn.BCELoss()\n",
        "\n",
        "  return discriminator, optimizer, criterion\n",
        "\n",
        "\n",
        "\n",
        "discriminator, optimizer, criterion = create_discriminator()"
      ],
      "metadata": {
        "id": "AQUHJT9LfNWt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in discriminator.parameters())\n",
        "trainable_params = sum(p.numel() for p in discriminator.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXGjwSZ7gZ4D",
        "outputId": "40c9ea29-283a-4bff-b822-66756ad3404d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Parameters: 40,705\n",
            "Trainable Parameters: 40,705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Phase 2.2 Setup Training for Discriminator"
      ],
      "metadata": {
        "id": "zXICKwmxgqZH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kgsg7LU3gk-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}